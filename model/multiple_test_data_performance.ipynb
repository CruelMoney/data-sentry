{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to test the performance of the pipeline on mutiple test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1 = pd.read_csv(\"../clean_data/Cleaned_test_text_with_pii_2018_12_31_05_35_46_815414.csv\")\n",
    "test_data_2 = pd.read_csv(\"../clean_data/Cleaned_test_text_with_pii_2019_01_18_06_21_07_588706.csv\")\n",
    "test_data_3 = pd.read_csv(\"../clean_data/Cleaned_test_text_with_pii_2019_01_18_06_39_35_811991.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from w2vpipe.pipeline import text_clean, word_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_pipe = joblib.load( 'word2vec_pipe_cv_production.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/80000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming while training word2vec model with new data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80000/80000 [00:08<00:00, 8987.96it/s] \n",
      "100%|██████████| 80000/80000 [00:00<00:00, 221243.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     10000\n",
      "           1       0.99      0.99      0.99     70000\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     80000\n",
      "   macro avg       0.97      0.97      0.97     80000\n",
      "weighted avg       0.99      0.99      0.99     80000\n",
      "\n",
      "CPU times: user 31.7 s, sys: 8.37 s, total: 40 s\n",
      "Wall time: 20.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "binary_pred = word2vec_pipe.predict(test_data_1[\"Text\"])\n",
    "binary_true = test_data_1[\"Target\"]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true = binary_true, y_pred = binary_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/80000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming while training word2vec model with new data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80000/80000 [00:09<00:00, 8538.03it/s] \n",
      "100%|██████████| 80000/80000 [00:00<00:00, 218832.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.95     10000\n",
      "           1       0.99      1.00      0.99     70000\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     80000\n",
      "   macro avg       0.98      0.96      0.97     80000\n",
      "weighted avg       0.99      0.99      0.99     80000\n",
      "\n",
      "CPU times: user 32.8 s, sys: 8.53 s, total: 41.4 s\n",
      "Wall time: 21.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "binary_pred = word2vec_pipe.predict(test_data_2[\"Text\"])\n",
    "binary_true = test_data_2[\"Target\"]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true = binary_true, y_pred = binary_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/80000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming while training word2vec model with new data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80000/80000 [00:09<00:00, 8801.63it/s] \n",
      "100%|██████████| 80000/80000 [00:00<00:00, 222339.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95     10000\n",
      "           1       0.99      1.00      0.99     70000\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     80000\n",
      "   macro avg       0.98      0.96      0.97     80000\n",
      "weighted avg       0.99      0.99      0.99     80000\n",
      "\n",
      "CPU times: user 33.1 s, sys: 9.38 s, total: 42.5 s\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "binary_pred = word2vec_pipe.predict(test_data_3[\"Text\"])\n",
    "binary_true = test_data_3[\"Target\"]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true = binary_true, y_pred = binary_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to make sure that the PII in test data does not appear too often in train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../clean_data/Cleaned_train_text_with_pii_2018_12_29_07_26_56_266227.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to calculate the PII overlap in training and test data\n",
    "# while excluding the 'None'. \n",
    "def pii_overlap(test, train):\n",
    "    \n",
    "    overlap_pii_binary = test.isin(train)\n",
    "    total_overlap = sum(overlap_pii_binary)\n",
    "    \n",
    "    none_type_num = sum(test == \"None\")\n",
    "    \n",
    "    pii_overlap_num = total_overlap - none_type_num\n",
    "    \n",
    "    return pii_overlap_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10992"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pii_overlap(test_data_1['PII'], train_data['PII'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11056"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pii_overlap(test_data_2['PII'], train_data['PII'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11097"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pii_overlap(test_data_3['PII'], train_data['PII'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to get all the overlap values\n",
    "def pii_overlap_value(test, train):\n",
    "    \n",
    "    overlap_pii_binary = test.isin(train)\n",
    "    none_type_binary = test != \"None\"\n",
    "    \n",
    "    combined_binary = none_type_binary & overlap_pii_binary\n",
    "    \n",
    "    return test.loc[combined_binary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Michael        72\n",
       "Smith          63\n",
       "Thomas         62\n",
       "Williams       61\n",
       "John           55\n",
       "David          54\n",
       "Joseph         47\n",
       "James          46\n",
       "Christopher    44\n",
       "Matthew        43\n",
       "Stephanie      42\n",
       "Jennifer       41\n",
       "Rodriguez      41\n",
       "Wilson         40\n",
       "Mark           38\n",
       "Name: PII, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pii_overlap_value(test_data_3['PII'], train_data['PII']).value_counts().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of the overlap in PII value originates from the name, which is reasonable since name does not have as much variation as other PIIs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total PII overlap between training data and test data is about 1/7 of the test data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In conclusion, the entire pipeline does works on unseen PII data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
