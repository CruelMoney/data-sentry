{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to train a word2vec model for the fake text with PII "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "from yellowbrick.text import TSNEVisualizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_pii = pd.read_csv(\"../data/text_with_pii_2018_12_21_04_32_47_173911.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Labels</th>\n",
       "      <th>PII</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ever watch television read measure almost. Tho...</td>\n",
       "      <td>Address</td>\n",
       "      <td>Suite 971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Impact region card 37271 Adams Road Suite 438 ...</td>\n",
       "      <td>Address</td>\n",
       "      <td>37271 Adams Road Suite 438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0604 Mason Wall Throughout admit have science ...</td>\n",
       "      <td>Address</td>\n",
       "      <td>0604 Mason Wall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Able item bag my day impact continue. Apt. 633...</td>\n",
       "      <td>Address</td>\n",
       "      <td>Apt. 633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inside perhaps Suite 744 else seven. Able seas...</td>\n",
       "      <td>Address</td>\n",
       "      <td>Suite 744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text   Labels  \\\n",
       "0  Ever watch television read measure almost. Tho...  Address   \n",
       "1  Impact region card 37271 Adams Road Suite 438 ...  Address   \n",
       "2  0604 Mason Wall Throughout admit have science ...  Address   \n",
       "3  Able item bag my day impact continue. Apt. 633...  Address   \n",
       "4  Inside perhaps Suite 744 else seven. Able seas...  Address   \n",
       "\n",
       "                          PII  \n",
       "0                   Suite 971  \n",
       "1  37271 Adams Road Suite 438  \n",
       "2             0604 Mason Wall  \n",
       "3                    Apt. 633  \n",
       "4                   Suite 744  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_pii.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Impact region card 37271 Adams Road Suite 438 technology indicate. Station cut rule church Congress. There west parent write. Accept image region through group matter.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_pii.iloc[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the text in a sentence and return a sentence.\n",
    "def clean_sentence(sentence):\n",
    "    \n",
    "    sentence_cleaned = [word.replace(\",\", \"\").replace(\".\", \"\")\\\n",
    "                        .lower() for word in sentence.split(\" \")]\n",
    "    return \" \".join(sentence_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ever watch television read measure almost thought shake take suite 971 program interest strong exist clear least like create most order court build organization'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentence(fake_pii.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.4 s, sys: 62.7 ms, total: 7.46 s\n",
      "Wall time: 7.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "context_sentences = fake_pii[\"Text\"].apply(clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence_word_list = [sentence.split(\" \")\\\n",
    "                                for sentence in context_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 16s, sys: 940 ms, total: 3min 17s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "word2vec_model_fake_pii = Word2Vec(tokenized_sentence_word_list,\\\n",
    "                                   size = 300, window=5,\n",
    "                                  min_count = 1, workers = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the trained word2vec model, we can save it to disk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model_fake_pii.save(\"./word2vec/word2vec_300_fake_pii.bin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
