{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to retrain the pipeline using the best parameters found \n",
    "to reduce the model size of 1.2G. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from w2vpipe.pipeline import word_embedding, text_clean\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_clf_word2vec = LogisticRegression(solver = \"lbfgs\", max_iter = 10000, C = 4.032\\\n",
    "                                        , class_weight = {0: 0.8, 1: 0.2})\n",
    "\n",
    "word2vec_pipe = Pipeline([('text_cleaning', text_clean()),\n",
    "                 (\"word_embedding\", word_embedding(algo_name = \"word2vec\", workers =2, size = 300)),\n",
    "                 (\"logit_clf_word2vec\",logit_clf_word2vec)\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"../clean_data/Cleaned_train_text_with_pii_2018_12_29_07_26_56_266227.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building new vocabulary and training the word2vec model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/800000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming while training word2vec model with new data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800000/800000 [01:27<00:00, 9183.85it/s] \n",
      "100%|██████████| 800000/800000 [00:03<00:00, 222464.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 26s, sys: 1min 39s, total: 12min 6s\n",
      "Wall time: 5min 34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('text_cleaning', <w2vpipe.pipeline.text_clean object at 0x7f0f8f632a90>), ('word_embedding', word_embedding(algo_name='word2vec', continue_train_pre_train=True,\n",
       "        dump_file=False, epochs=5, min_count=1, pre_train=None,\n",
       "        re_train_new_sentences=True, size=300, window=5, workers=2)...enalty='l2', random_state=None,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "word2vec_pipe.fit(train_data['Text'], train_data['Target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is about 1.1GB since I choose to use a vector length of 300 to embed the words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word2vec_pipe_production.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(word2vec_pipe, 'word2vec_pipe_production.pkl', compress = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance the model size and model performance in the future by changing the size of vector embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if the performance is still the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"../clean_data/Cleaned_test_text_with_pii_\\\n",
    "2018_12_31_05_35_46_815414.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/80000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforming while training word2vec model with new data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80000/80000 [00:09<00:00, 8524.90it/s] \n",
      "100%|██████████| 80000/80000 [00:00<00:00, 217229.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92     10000\n",
      "           1       1.00      0.98      0.99     70000\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     80000\n",
      "   macro avg       0.93      0.97      0.95     80000\n",
      "weighted avg       0.98      0.98      0.98     80000\n",
      "\n",
      "CPU times: user 32.7 s, sys: 8.23 s, total: 41 s\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "binary_pred = word2vec_pipe.predict(test_data[\"Text\"])\n",
    "binary_true = test_data[\"Target\"]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true = binary_true, y_pred = binary_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
